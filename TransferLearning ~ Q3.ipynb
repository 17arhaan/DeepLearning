{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._C'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n",
      "File \u001b[1;32mc:\\Users\\Arhaan\\Documents\\Coding\\DeepLearning\\.venv\\Lib\\site-packages\\torch\\nn\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     Buffer \u001b[38;5;28;01mas\u001b[39;00m Buffer,\n\u001b[0;32m      4\u001b[0m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[0;32m      5\u001b[0m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[0;32m      6\u001b[0m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     attention \u001b[38;5;28;01mas\u001b[39;00m attention,\n\u001b[0;32m     11\u001b[0m     functional \u001b[38;5;28;01mas\u001b[39;00m functional,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[0;32m     17\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Arhaan\\Documents\\Coding\\DeepLearning\\.venv\\Lib\\site-packages\\torch\\nn\\parameter.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _disabled_torch_function_impl\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Metaclass to combine _TensorMeta and the instance check override for Parameter.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_ParameterMeta\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_TensorMeta):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Make `isinstance(t, Parameter)` return True for custom tensor instances that have the _is_param flag.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch._C'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckpointHandler:\n",
    "    def __init__(self, best_valid_loss=float('inf')):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "    \n",
    "    def save_best_model(self, state, filename):\n",
    "        if state['loss'] < self.best_valid_loss:\n",
    "            self.best_valid_loss = state['loss']\n",
    "            torch.save(state, filename)\n",
    "            print('checkpoint file updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1, 32, kernel_size= 3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2, 2), stride= 2),\n",
    "                                 nn.Conv2d(32, 64, kernel_size= 3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2, 2), stride= 2),\n",
    "                                 nn.Conv2d(64, 32, kernel_size= 3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2, 2), stride= 2)\n",
    "                                 )\n",
    "        self.classify_head = nn.Sequential(nn.Flatten(),\n",
    "                                           nn.Linear(32, 20, bias= True),\n",
    "                                           nn.Linear(20, 10, bias= True))\n",
    "    def forward(self, x):\n",
    "        return self.classify_head(self.net(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.to('cuda')\n",
    "optimizer = optim.SGD(model.parameters(), lr= 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "checkpoint_handler = CheckpointHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
    "train = datasets.MNIST('.', train= True, download= True, transform= transforms)\n",
    "test = datasets.MNIST('.', download= True, train= False, transform= transforms)\n",
    "train_loader = DataLoader(train, batch_size= 64, shuffle= True)\n",
    "test_loader = DataLoader(test, batch_size= 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch - {epoch}, loss = {running_loss}')\n",
    "\n",
    "    state = {'epoch': epoch,\n",
    "             'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict': optimizer.state_dict(),\n",
    "             'loss': running_loss}\n",
    "\n",
    "    checkpoint_handler.save_best_model(state, './q3_checkpoints/checkpoint_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retraining\n",
    "model = CNN()\n",
    "checkpoint = torch.load('./q3_checkpoints/checkpoint_best.pth', weights_only= False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cuda')\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch - {epoch}, loss = {running_loss}')\n",
    "\n",
    "    state = {'epoch': epoch,\n",
    "             'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict': optimizer.state_dict(),\n",
    "             'loss': running_loss}\n",
    "\n",
    "    checkpoint_handler.save_best_model(state, './q3_checkpoints/checkpoint_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds, all_target = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        input, target = input.to('cuda'), target.to('cuda')\n",
    "        output = model(input)\n",
    "        val, index = torch.max(output, dim= 1)\n",
    "        all_preds.extend(index.to('cpu'))\n",
    "        all_target.extend(target.to('cpu'))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(all_preds, all_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
